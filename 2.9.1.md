# 流量问题

## 将需求的value(流量对象) 整合为一个bean    实现序列化


创建Mapper  和 Reduce

Mapper 
获取所需字符串 正则分割  将 电话号 上行 下行 取出

通过有参构造 将需求的内容整合在一起  如题 需求总流量 在构造时直接将总流量构造出来

注意:  类型的转换    bean中的构造需要实现WriterableComparable
	   序列化与反序列化  要非常注意 序列化与反序列化数据的对应顺序
	   
要使用自定义的类型作为输出
1. 	要根据我们的数据进行建模(创建实体类)
2. 	根据建好的模型 考虑Mapper形参怎么写,map()方法中怎么对数据进行切割筛选 将我们的数据放入自定义的bean中
	想好将bean以key还是value进行输出
3. 	调用context.writer方法 
4. 	map的结果最终要写入到磁盘中,所以要注意我们自定义的bean一定要支持序列化
	Serializable是JAVA提供的重量级序列化,在hadoop中更建议使用hadoop自身提供的WriterableComparable
	来实现序列化与反序列化
5.	这时候有write()写入文件和readFields()从文件红读取  这两个方法需要我们实现 否则在reduce阶段是获取不到数据的,
	而这里一定要注意的一点是 : readfiles()方法中调用read方法时一定要按照写入的顺序进行读取
	对我们的属性进行赋值,否则会混乱 uploadStream = paramDataInput.readInt();
6.	reduce当中要注意形参和输出位置,以及在driver区的指定输出数据的格式
	job.setOutputKeyClass(.class)
	job.setoutputvalueClass(.class)
7.	当这些都处理好之后,我们的reduce后的结果就可以输出到我们指定的位置了 但是要注意自定义的
	bean的tostring()方法的重写,否则输出也不会是我们需要的

	


